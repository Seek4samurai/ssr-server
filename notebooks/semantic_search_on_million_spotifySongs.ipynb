{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8224a837-b3a3-4245-add2-901962246479",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS MIGHT NEED TO BE FIXED TO RUN THESE CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e681c0-12c2-4f1f-9336-a124cc049230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Documents\\projects\\cli-tool\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9407/9407 [09:56<00:00, 15.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Used dataset : https://www.kaggle.com/datasets/joebeachcapital/30000-spotify-songs/data\n",
    "# https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import ast\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(torch.cuda.is_available())  # True\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "df = pd.read_csv(\"./dataset/millionSongs.csv\")\n",
    "\n",
    "df[\"artists\"] = df[\"artists\"].apply(ast.literal_eval)\n",
    "\n",
    "def build_semantic_text(row):\n",
    "    artists = \", \".join(row[\"artists\"])\n",
    "    return (\n",
    "        f\"Song: {row['name']} by {artists}. \"\n",
    "        f\"Album: {row['album']}. Released in {row['year']} on {row['release_date']}. \"\n",
    "        f\"This track is characterized by danceability {row['danceability']}, energy {row['energy']}, \"\n",
    "        f\"valence {row['valence']}, acousticness {row['acousticness']}, instrumentalness {row['instrumentalness']}, \"\n",
    "        f\"speechiness {row['speechiness']}, liveness {row['liveness']}, loudness {row['loudness']}, \"\n",
    "        f\"and tempo {row['tempo']} BPM. \"\n",
    "        f\"It has a key of {row['key']}, mode {row['mode']}, and a time signature of {row['time_signature']}. \"\n",
    "        f\"Duration: {row['duration_ms']} milliseconds.\"\n",
    "    )\n",
    "\n",
    "df[\"semantic_text\"] = df.apply(build_semantic_text, axis=1)\n",
    "\n",
    "texts = df[\"semantic_text\"].tolist()\n",
    "\n",
    "embeddings = model.encode(texts, batch_size=128, device=\"cuda\", show_progress_bar=True)\n",
    "\n",
    "# df[\"embedding\"] = df[\"semantic_text\"].apply(lambda x: model.encode(x).tolist())\n",
    "\n",
    "df[\"embedding\"] = embeddings.tolist()\n",
    "\n",
    "with open(\"./million_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c8e2d-35cd-4bba-8feb-8f007bb7238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(torch.cuda.is_available())  # True\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a57838d0-0ef1-4acb-82cc-4b38ac90a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1204025, 384)\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"./million_embeddings.pkl\", \"rb\") as f:\n",
    "#     df = pickle.load(f)\n",
    "\n",
    "embeddings = df[\"embedding\"]\n",
    "\n",
    "#embeddings_np = np.array(embeddings)  # shape: (num_songs, 384) this is giving 1D arrray\n",
    "embeddings_np = np.stack(df[\"embedding\"].values).astype(\"float32\")  # shape: (num_songs, 384)\n",
    "print(embeddings_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cef6457-0cbd-482f-a543-f300b9df6b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in index: 1204025\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "d = embeddings_np.shape[1]  # embedding dimension (384)\n",
    "index = faiss.IndexFlatIP(d)\n",
    "\n",
    "faiss.normalize_L2(embeddings_np)\n",
    "\n",
    "index.add(embeddings_np)\n",
    "\n",
    "print(\"Number of vectors in index:\", index.ntotal)\n",
    "faiss.write_index(index, \"songs.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c969988-117f-4c15-93cb-6b19f03e7340",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faiss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m index = \u001b[43mfaiss\u001b[49m.read_index(\u001b[33m\"\u001b[39m\u001b[33m./songs.index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m q = \u001b[33m\"\u001b[39m\u001b[33mThe Young God Speaks\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m q_emb = model.encode(q).astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m).reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'faiss' is not defined"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"./songs.index\")\n",
    "\n",
    "q = \"The Young God Speaks\"\n",
    "q_emb = model.encode(q).astype(\"float32\").reshape(1, -1)\n",
    "\n",
    "faiss.normalize_L2(q_emb)\n",
    "\n",
    "score, index = index.search(q_emb, 10)\n",
    "\n",
    "for idx, scr in zip(index[0], score[0]):\n",
    "    print(f\"Song: {df['name'].iloc[idx]} : {scr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb66e285-aafa-4b68-99c5-6b2f9bc8ac92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f668f-0e36-47c1-b063-d5f2c61c3f42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This works but is slow af for data with millions of items\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def cosine_similarity_np(A, B):\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    return np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "\n",
    "q = \"pop\"\n",
    "q_emb = model.encode(q)\n",
    "q_emb = q_emb.reshape(1, -1)          # shape: (1, 384)\n",
    "\n",
    "similarities = (embeddings_np @ q_emb.T).flatten()  # dot product\n",
    "similarities /= np.linalg.norm(embeddings_np, axis=1)\n",
    "similarities /= np.linalg.norm(q_emb)\n",
    "\n",
    "top_idx = np.argsort(-similarities)[:10]\n",
    "\n",
    "for i in top_idx:\n",
    "    print(f\"{df['name'][i]}: {similarities[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb60113-1c95-4438-96c1-e3f09d4c8655",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- Slowest approch below ---\n",
    "    \n",
    "# similarities = [cosine_similarity_np(q_emb, song_emb) for song_emb in embeddings]\n",
    "    \n",
    "# songs = df[\"name\"]\n",
    "\n",
    "# results = list(zip(songs, similarities))\n",
    "\n",
    "# # Sort by similarity descending\n",
    "# results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Top 10 similar songs\n",
    "# top_10 = results[:10]\n",
    "\n",
    "# for song, score in top_10:\n",
    "#     print(f\"{song}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29615cd-7751-448d-a858-f7fb1f58b743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1074"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# del df\n",
    "# del texts\n",
    "# del embeddings\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191e247-2b10-4056-8f10-9ab932a86d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
